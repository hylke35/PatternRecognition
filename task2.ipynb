{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.semi_supervised import LabelPropagation, LabelSpreading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"data/creditcard.csv\", index_col=0)\n",
    "\n",
    "# Ignore 'Time' and 'Amount' columns, keep only the encoded values (V1 to V28) and 'Class' (labels)\n",
    "X = data.drop(columns=['Class', 'Amount'])\n",
    "y = data['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/\n",
    "smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into 80% train and 20% test, stratify to maintain class balance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, stratify=y_balanced, random_state=42)\n",
    "\n",
    "# Further split train set into 30% labeled and 70% unlabeled\n",
    "X_train_lab, X_train_unlab, y_train_lab, y_train_unlab = train_test_split(X_train, y_train, test_size=0.7, stratify=y_train, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set (labeled): (136471, 28), Train set (unlabeled): (318433, 28), Test set: (113726, 28)\n"
     ]
    }
   ],
   "source": [
    "# Standardize features (important for SVM and other classifiers)\n",
    "scaler = StandardScaler()\n",
    "X_train_lab = scaler.fit_transform(X_train_lab)\n",
    "X_train_unlab = scaler.transform(X_train_unlab)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f'Train set (labeled): {X_train_lab.shape}, Train set (unlabeled): {X_train_unlab.shape}, Test set: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.9954\n",
      "F1 Score on the test set: 0.9954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     56863\n",
      "           1       0.99      1.00      1.00     56863\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# svm = SVC()\n",
    "\n",
    "# param_grid = {\n",
    "#     'C': [0.1, 1, 10],\n",
    "#     'gamma': ['scale', 'auto'],\n",
    "#     'degree': [2, 3],\n",
    "#     'kernel': ['linear', 'rbf', 'poly']\n",
    "# }\n",
    "\n",
    "# grid_search = GridSearchCV(svm, param_grid, cv=3, verbose=2, n_jobs=-1)\n",
    "# grid_search.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "# print(f'Best parameters: {grid_search.best_params_}')\n",
    "# Best parameters: {'C': 10, 'degree': 2, 'gamma': 'scale', 'kernel': 'rbf'}\n",
    "\n",
    "best_svm = SVC(C=10, degree=2, gamma='scale', kernel='rbf')\n",
    "best_svm.fit(X_train_lab, y_train_lab)\n",
    "\n",
    "# best_svm = grid_search.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy on the test set: {accuracy:.4f}')\n",
    "print(f'F1 Score on the test set: {f1:.4f}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test set: 0.9972\n",
      "F1 Score on the test set: 0.9972\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      1.00      1.00     56863\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hwest\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\semi_supervised\\_label_propagation.py:230: RuntimeWarning: invalid value encountered in divide\n",
      "  probabilities /= normalizer\n"
     ]
    }
   ],
   "source": [
    "y_train_unlab[:] = -1\n",
    "\n",
    "X_train_combined = np.vstack((X_train_lab, X_train_unlab))\n",
    "y_train_combined = np.hstack((y_train_lab, y_train_unlab))\n",
    "\n",
    "# label_spread_model = LabelSpreading(kernel='knn', n_neighbors=7, max_iter=1000)\n",
    "label_prop_model = LabelPropagation(kernel='knn', n_neighbors=7, max_iter=1000)\n",
    "\n",
    "# label_spread_model.fit(X_train_combined, y_train_combined)\n",
    "label_prop_model.fit(X_train_combined, y_train_combined)\n",
    "\n",
    "# y_pred_test = label_spread_model.predict(X_test)\n",
    "y_pred_test = label_prop_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_test)\n",
    "f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(f'Accuracy on the test set: {accuracy:.4f}')\n",
    "print(f'F1 Score on the test set: {f1:.4f}')\n",
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero rows in X_train_combined: 0\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of zero rows in X_train_combined: {np.sum(np.all(X_train_combined == 0, axis=1))}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_complete: (454904, 28)\n",
      "Shape of y_train_complete: (454904,)\n",
      "Final Accuracy on the test set: 0.9975\n",
      "Final F1 Score on the test set: 0.9975\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56863\n",
      "           1       1.00      1.00      1.00     56863\n",
      "\n",
      "    accuracy                           1.00    113726\n",
      "   macro avg       1.00      1.00      1.00    113726\n",
      "weighted avg       1.00      1.00      1.00    113726\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_complete = np.vstack((X_train_lab, X_train_unlab))\n",
    "y_train_complete = label_prop_model.transduction_\n",
    "\n",
    "print(f'Shape of X_train_complete: {X_train_complete.shape}')\n",
    "print(f'Shape of y_train_complete: {y_train_complete.shape}')\n",
    "\n",
    "assert X_train_complete.shape[0] == y_train_complete.shape[0], \"Mismatch between features and labels\"\n",
    "\n",
    "best_svm.fit(X_train_complete, y_train_complete)\n",
    "\n",
    "y_pred_test_final = best_svm.predict(X_test)\n",
    "\n",
    "accuracy_final = accuracy_score(y_test, y_pred_test_final)\n",
    "f1_final = f1_score(y_test, y_pred_test_final)\n",
    "\n",
    "print(f'Final Accuracy on the test set: {accuracy_final:.4f}')\n",
    "print(f'Final F1 Score on the test set: {f1_final:.4f}')\n",
    "print(classification_report(y_test, y_pred_test_final))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
